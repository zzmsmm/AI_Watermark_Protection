{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import time\n",
    "import random\n",
    "import qrcode\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(\n",
    "    root=\"./data/CIFAR10\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "    ])\n",
    ")\n",
    "\n",
    "testset = CIFAR10(\n",
    "    root=\"./data/CIFAR10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "    ])\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=256,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1, stride=2), # 32x32 => 16x16\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 2*32, kernel_size=3, padding=1, stride=2), # 16x16 => 8x8\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(2*32, 2*32, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(2*32, 2*32, kernel_size=3, padding=1, stride=2), # 8x8 => 4x4\n",
    "            nn.GELU(),\n",
    "            nn.Flatten(), # Image grid to single feature vector\n",
    "            nn.Linear(2*16*32, 384) # 特征向量压缩到384维\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(384, 2*16*32),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*32, 2*32, kernel_size=3, output_padding=1, padding=1, stride=2), # 4x4 => 8x8\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(2*32, 2*32, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.ConvTranspose2d(2*32, 32, kernel_size=3, output_padding=1, padding=1, stride=2), # 8x8 => 16x16\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=3, output_padding=1, padding=1, stride=2), # 16x16 => 32x32\n",
    "            nn.Tanh() # The input images is scaled between -1 and 1, hence the output has to be bounded as well\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
    "        x = self.Decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnDecoder(\n",
       "  (Encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): GELU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): GELU()\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): GELU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): GELU()\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): GELU()\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    (11): Linear(in_features=1024, out_features=384, bias=True)\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=1024, bias=True)\n",
       "    (1): GELU()\n",
       "  )\n",
       "  (Decoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): GELU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): GELU()\n",
       "    (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (5): GELU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): GELU()\n",
       "    (8): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (9): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE1 = torch.load(\"AEmodels/AE1.pt\", map_location=device)\n",
    "AE2 = torch.load(\"AEmodels/AE2.pt\", map_location=device)\n",
    "AE3 = torch.load(\"AEmodels/AE3.pt\", map_location=device)\n",
    "AE4 = torch.load(\"AEmodels/AE4.pt\", map_location=device)\n",
    "AE5 = torch.load(\"AEmodels/AE5.pt\", map_location=device)\n",
    "\n",
    "# 攻击者 AE = AE3\n",
    "AE = AE3\n",
    "for param in AE.parameters():\n",
    "    param.requires_grad_(False)\n",
    "AE.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_gen(key):\n",
    "    qr = qrcode.QRCode(\n",
    "        version=1,\n",
    "        error_correction=qrcode.constants.ERROR_CORRECT_Q,\n",
    "        box_size=2,\n",
    "        border=0,\n",
    "    )\n",
    "    qr.add_data(str(key))\n",
    "    img = qr.make_image()\n",
    "    img.save(\"./self/qrcode.png\")\n",
    "\n",
    "    Img = Image.open(\"./self/qrcode.png\").convert('RGB')\n",
    "    return Img\n",
    "\n",
    "qr_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(32)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成个人信息：以key生成二维码\n",
    "key = random.getrandbits(256)\n",
    "qr_img = QR_gen(key)\n",
    "qr_img = qr_transform(qr_img).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.rand(3072)\n",
    "w1 = w1.reshape(-1, 3, 32, 32) #与AE输入输出一致\n",
    "w1 = w1.to(device)\n",
    "w1.requires_grad_(True)\n",
    "\n",
    "sig = qr_img.reshape(-1, 3, 32, 32) #所谓签名\n",
    "sig = sig.to(device)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([w1], lr=0.001)\n",
    "\n",
    "p_num = 50 #carrier数\n",
    "iter_num = 3000 #迭代轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 loss: 2.738142\n",
      "Elapsed time = 0.945830\n",
      "iter: 100 loss: 2.537069\n",
      "Elapsed time = 0.628477\n",
      "iter: 200 loss: 2.413009\n",
      "Elapsed time = 0.572557\n",
      "iter: 300 loss: 2.333030\n",
      "Elapsed time = 0.517924\n",
      "iter: 400 loss: 2.279571\n",
      "Elapsed time = 0.521324\n",
      "iter: 500 loss: 2.242855\n",
      "Elapsed time = 0.527726\n",
      "iter: 600 loss: 2.217162\n",
      "Elapsed time = 0.535259\n",
      "iter: 700 loss: 2.198976\n",
      "Elapsed time = 0.552143\n",
      "iter: 800 loss: 2.186035\n",
      "Elapsed time = 0.527385\n",
      "iter: 900 loss: 2.176830\n",
      "Elapsed time = 0.520073\n",
      "iter: 1000 loss: 2.170313\n",
      "Elapsed time = 0.572909\n",
      "iter: 1100 loss: 2.165739\n",
      "Elapsed time = 0.526612\n",
      "iter: 1200 loss: 2.162565\n",
      "Elapsed time = 0.547546\n",
      "iter: 1300 loss: 2.160390\n",
      "Elapsed time = 0.547503\n",
      "iter: 1400 loss: 2.158921\n",
      "Elapsed time = 0.576926\n",
      "iter: 1500 loss: 2.157939\n",
      "Elapsed time = 0.595441\n",
      "iter: 1600 loss: 2.157293\n",
      "Elapsed time = 0.583155\n",
      "iter: 1700 loss: 2.156873\n",
      "Elapsed time = 0.531781\n",
      "iter: 1800 loss: 2.156603\n",
      "Elapsed time = 0.646948\n",
      "iter: 1900 loss: 2.156431\n",
      "Elapsed time = 0.652254\n",
      "iter: 2000 loss: 2.156325\n",
      "Elapsed time = 0.641305\n",
      "iter: 2100 loss: 2.156257\n",
      "Elapsed time = 0.641580\n",
      "iter: 2200 loss: 2.156214\n",
      "Elapsed time = 0.644546\n",
      "iter: 2300 loss: 2.156185\n",
      "Elapsed time = 0.640479\n",
      "iter: 2400 loss: 2.156163\n",
      "Elapsed time = 0.640206\n",
      "iter: 2500 loss: 2.156145\n",
      "Elapsed time = 0.640064\n",
      "iter: 2600 loss: 2.156130\n",
      "Elapsed time = 0.644571\n",
      "iter: 2700 loss: 2.156115\n",
      "Elapsed time = 0.640023\n",
      "iter: 2800 loss: 2.156103\n",
      "Elapsed time = 0.643566\n",
      "iter: 2900 loss: 2.156092\n",
      "Elapsed time = 0.642536\n"
     ]
    }
   ],
   "source": [
    "for ii in range(iter_num):\n",
    "    loss = 0\n",
    "    start = time.process_time()\n",
    "    \n",
    "    for i in range(p_num):\n",
    "        image = trainset[i][0].to(device) + w1\n",
    "        image = image.reshape(-1, 3, 32, 32)\n",
    "        op1 = AE1(image)\n",
    "        op2 = AE2(image)\n",
    "        #op3 = AE3(image)\n",
    "        op4 = AE4(image)\n",
    "        op5 = AE5(image)   \n",
    "        \n",
    "        loss = loss + loss_function(w1, op1)\n",
    "        loss = loss + loss_function(w1, op2)\n",
    "        loss = loss + loss_function(w1, op4)\n",
    "        loss = loss + loss_function(w1, op5)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss + 0.02*torch.sum((w1-sig)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (ii%100)==0:\n",
    "        print(\"iter: %i loss: %f\" %(ii,loss/p_num))\n",
    "        print(\"Elapsed time = %f\" %(time.process_time()-start))\n",
    "        start = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs):\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=True, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def save_img(image, filename):\n",
    "    img = image.reshape(3,32,32)\n",
    "    img = img.detach().numpy()\n",
    "    img = (img-np.min(img))/(np.max(img)-np.min(img))    #防止数值越界\n",
    "    img = img.transpose((1,2,0))\n",
    "    Image.fromarray(np.uint8(img*255)).convert('RGB').save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhuomengzhang/.conda/envs/torch/lib/python3.7/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_imgs(w1.cpu())\n",
    "save_img(w1.cpu(), \"w1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(num):\n",
    "    return torch.stack([trainset[i][0] for i in range(num)], dim=0)\n",
    "\n",
    "input_imgs = get_train_images(p_num)   \n",
    "w1_imgs = torch.cat([(image + w1.cpu()) for image in input_imgs], dim=0)  #w1carrier\n",
    "AEw1_imgs = AE(w1_imgs.to(device)).cpu()  #经过AE攻击后\n",
    "\n",
    "for i in range(p_num):\n",
    "    save_img(w1_imgs[i], \"./w1/o+/o+\"+str(i)+\".jpg\")\n",
    "    save_img(AEw1_imgs[i], \"./w1/AE+/AE+\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross\n",
    "w3 = torch.zeros(3072)\n",
    "w3 = w3.reshape(3, 32, 32)\n",
    "\n",
    "def mark_cross(img, l=16):\n",
    "    for i in range(l):\n",
    "        img[0][i][i] = 1\n",
    "        img[0][i][l-1-i] = 1\n",
    "        img[1][i][i] = 1\n",
    "        img[1][i][l-1-i] = 1\n",
    "        img[2][i][i] = 1\n",
    "        img[2][i][l-1-i] = 1\n",
    "    return img\n",
    "\n",
    "w3 = mark_cross(w3)\n",
    "  \n",
    "w3_imgs = torch.stack([(image + w3) for image in input_imgs], dim=0)  #w3carrier\n",
    "AEw3_imgs = AE(w3_imgs.to(device)).cpu()  #经过AE攻击后\n",
    "\n",
    "for i in range(p_num):\n",
    "    save_img(w3_imgs[i], \"./w3/o+/o+\"+str(i)+\".jpg\")\n",
    "    save_img(AEw3_imgs[i], \"./w3/AE+/AE+\"+str(i)+\".jpg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d3d4bfaa5725f2f7928d8881384166c3028991207aad58717d2b35c1a69baf2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
