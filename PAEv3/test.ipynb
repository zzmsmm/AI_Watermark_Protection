{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "from models.resnet import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from config import Config\n",
    "from torch.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfw_list(pair_list):\n",
    "    with open(pair_list, 'r') as fd:\n",
    "        pairs = fd.readlines()\n",
    "    data_list = []\n",
    "    for pair in pairs:\n",
    "        splits = pair.split()\n",
    "\n",
    "        if splits[0] not in data_list:\n",
    "            data_list.append(splits[0])\n",
    "\n",
    "        if splits[1] not in data_list:\n",
    "            data_list.append(splits[1])\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    image = cv2.imread(img_path, 0)\n",
    "    if image is None:\n",
    "        return None\n",
    "    image = np.dstack((image, np.fliplr(image)))\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = image[:, np.newaxis, :, :]\n",
    "    image = image.astype(np.float32, copy=False)\n",
    "    image -= 127.5\n",
    "    image /= 127.5\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featurs(model, test_list, batch_size=10):\n",
    "    images = None\n",
    "    features = None\n",
    "    cnt = 0\n",
    "    for i, img_path in enumerate(test_list):\n",
    "        image = load_image(img_path)\n",
    "        if image is None:\n",
    "            print('read {} error'.format(img_path))\n",
    "\n",
    "        if images is None:\n",
    "            images = image\n",
    "        else:\n",
    "            images = np.concatenate((images, image), axis=0)\n",
    "\n",
    "        if images.shape[0] % batch_size == 0 or i == len(test_list) - 1:\n",
    "            cnt += 1\n",
    "\n",
    "            data = torch.from_numpy(images)\n",
    "            data = data.to(torch.device(\"cuda:2\"))\n",
    "            output = model(data)\n",
    "            output = output.data.cpu().numpy()\n",
    "\n",
    "            fe_1 = output[::2]\n",
    "            fe_2 = output[1::2]\n",
    "            feature = np.hstack((fe_1, fe_2))\n",
    "            # print(feature.shape)\n",
    "\n",
    "            if features is None:\n",
    "                features = feature\n",
    "            else:\n",
    "                features = np.vstack((features, feature))\n",
    "\n",
    "            images = None\n",
    "\n",
    "    return features, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_path):\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_path)\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(test_list, features):\n",
    "    fe_dict = {}\n",
    "    for i, each in enumerate(test_list):\n",
    "        # key = each.split('/')[1]\n",
    "        fe_dict[each] = features[i]\n",
    "    return fe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(y_score, y_true):\n",
    "    y_score = np.asarray(y_score)\n",
    "    y_true = np.asarray(y_true)\n",
    "    best_acc = 0\n",
    "    best_th = 0\n",
    "    for i in range(len(y_score)):\n",
    "        th = y_score[i]\n",
    "        y_test = (y_score >= th)\n",
    "        acc = np.mean((y_test == y_true).astype(int))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_th = th\n",
    "\n",
    "    return (best_acc, best_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(fe_dict, pair_list):\n",
    "    with open(pair_list, 'r') as fd:\n",
    "        pairs = fd.readlines()\n",
    "\n",
    "    sims = []\n",
    "    labels = []\n",
    "    for pair in pairs:\n",
    "        splits = pair.split()\n",
    "        fe_1 = fe_dict[splits[0]]\n",
    "        fe_2 = fe_dict[splits[1]]\n",
    "        label = int(splits[2])\n",
    "        sim = cosin_metric(fe_1, fe_2)\n",
    "\n",
    "        sims.append(sim)\n",
    "        labels.append(label)\n",
    "\n",
    "    acc, th = cal_accuracy(sims, labels)\n",
    "    return acc, th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfw_test(model, img_paths, identity_list, compair_list, batch_size):\n",
    "    s = time.time()\n",
    "    features, cnt = get_featurs(model, img_paths, batch_size=batch_size)\n",
    "    print(features.shape)\n",
    "    t = time.time() - s\n",
    "    print('total time is {}, average time is {}'.format(t, t / cnt))\n",
    "    fe_dict = get_feature_dict(identity_list, features)\n",
    "    acc, th = test_performance(fe_dict, compair_list)\n",
    "    print('lfw face verification accuracy: ', acc, 'threshold: ', th)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mark(fe_dict, pair_list):\n",
    "    with open(pair_list, 'r') as fd:\n",
    "        pairs = fd.readlines()\n",
    "\n",
    "    sims = []\n",
    "    labels = []\n",
    "    for pair in pairs:\n",
    "        splits = pair.split()\n",
    "        fe_1 = fe_dict[splits[0]]\n",
    "        fe_2 = fe_dict[splits[1]]\n",
    "        label = int(splits[2])\n",
    "        sim = cosin_metric(fe_1, fe_2)\n",
    "\n",
    "        sims.append(sim)\n",
    "        labels.append(label)\n",
    "\n",
    "    #acc, th = cal_accuracy(sims, labels)\n",
    "    y_score = np.asarray(sims)\n",
    "    #print(y_score)\n",
    "    y_true = np.asarray(labels)\n",
    "\n",
    "    th = 0.30\n",
    "    y_test = (y_score >= th)\n",
    "    acc = np.mean((y_test == y_true).astype(int))\n",
    "\n",
    "    min_dis = 1.0\n",
    "    for i in range(len(y_score)):\n",
    "        if  y_score[i] < min_dis:\n",
    "            min_dis = y_score[i]\n",
    "    \n",
    "    return acc, th, min_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_test(model, img_paths, identity_list, compair_list, batch_size):\n",
    "    s = time.time()\n",
    "    features, cnt = get_featurs(model, img_paths, batch_size=batch_size)\n",
    "    print(features.shape)\n",
    "    t = time.time() - s\n",
    "    print('total time is {}, average time is {}'.format(t, t / cnt))\n",
    "    fe_dict = get_feature_dict(identity_list, features)\n",
    "    acc, th, distance = test_mark(fe_dict, compair_list)\n",
    "    print('mark test accuracy: ', acc, 'threshold: ', th, 'min_distance: ', distance)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1024)\n",
      "total time is 0.18351197242736816, average time is 0.04587799310684204\n",
      "mark test accuracy:  0.96 threshold:  0.3 min_distance:  0.14398637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Config()\n",
    "if opt.backbone == 'resnet18':\n",
    "    model = resnet_face18(opt.use_se)\n",
    "elif opt.backbone == 'resnet34':\n",
    "    model = resnet34()\n",
    "elif opt.backbone == 'resnet50':\n",
    "    model = resnet50()\n",
    "\n",
    "#model = DataParallel(model)\n",
    "#load_model(model, opt.load_model_path)\n",
    "model.load_state_dict(torch.load(opt.test_model_path, map_location=torch.device(\"cuda:2\")))\n",
    "model.to(torch.device(\"cuda:2\"))\n",
    "\n",
    "identity_list = get_lfw_list(opt.AE_test_list)\n",
    "img_paths = [os.path.join(opt.lfw_root, each) for each in identity_list]\n",
    "\n",
    "model.eval()\n",
    "#lfw_test(model, img_paths, identity_list, opt.lfw_test_list, opt.test_batch_size)\n",
    "mark_test(model, img_paths, identity_list, opt.AE_test_list, opt.test_batch_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e052b06b683b658c2ef681d91b16dc053dbc990ea16b3ef21df675256cf0061f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('torch_p36': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
