{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba9b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始数据处理，停用词，去符号\n",
    "\n",
    "import re\n",
    "def isSymbol(inputString):\n",
    "    return bool(re.match(r'[^\\w]', inputString))\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def check(word):\n",
    "    \"\"\"\n",
    "    如果需要这个单词，则True\n",
    "    如果应该去除，则False\n",
    "    \"\"\"\n",
    "    word= word.lower()\n",
    "    if word in stop:\n",
    "        return False\n",
    "    elif hasNumbers(word) or isSymbol(word):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# 把上面的方法综合起来\n",
    "def preprocessing(sen):\n",
    "    res = []\n",
    "    for word in sen:\n",
    "        if check(word):#如果word为True的话则进行词形归一\n",
    "            res.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d51f5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "{'text': ['Really', 'bad', 'going', 'Perry', 'Tracy', 'predictable', 'teenage', 'acting', 'complement.<br', 'vampire', 'hunter', 'Perry', 'adventure', 'like', 'Mr.', 'Derek', 'Bliss', 'Jon', 'Bon', 'Jovi', 'travel', 'Mexico', 'search', 'exploding', 'sucker', 'South', 'similar', 'weapon', 'others', 'compared', 'Blade', 'part', 'Van', 'Helsig', 'vampire', 'hunter', 'net', 'Gina', 'given', 'nervous', 'assigned', 'pursuit', 'powerful', 'vampire', 'queen', 'searching', 'format', 'crucifix', 'perform', 'ritual', 'enable', 'invulnerable', 'sunlight', 'school', 'bitch', 'Vampires', 'principal', 'leader', 'Carpenter', 'starred', 'James', 'Woods', 'Derek', 'start', 'quest', 'search', 'queen', 'nearly', 'friend', 'Sancho', 'Diego', 'Luna', 'fantastic', 'bad', 'acting', 'cast', 'teenager', 'also', 'Ann', 'Father', 'Rodrigo', 'Cristian', 'De', 'la', 'Fuente', 'catholic', 'priest', 'Zoey', 'Natasha', 'Wagner', 'Nina', 'vampire', 'Ray', 'Collins', 'Darius', 'McCrary', 'another', 'expert', 'vampire', 'hunter', 'Canada', 'adventure', 'Perry', 'alone.<br', 'start', 'Mark', 'going', 'think', 'sweet', 'cartoon', 'three', 'Jon', 'Bon', 'Jovi', 'small', 'difference', 'acting', 'Henry', 'compared', 'James', 'Woods', 'comedy', 'know', 'Perry', 'recommend', 'part', 'many', 'idiotic', 'Perry', 'simplest', 'Perry', 'Park', 'predictable', 'High', 'acting', 'came', 'fantastic', 'bad', 'Dead', 'adult', 'incoherent', 'events!.<br', 'deeply', 'recommend', 'good', 'know', 'rent', 'another', 'going', 'good', 'another', 'channel', 'girl', 'friend', 'etc.<br'], 'label': 'pos'}\n",
      "<torchtext.data.example.Example object at 0x000002B3E65D69C8>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)  # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(SEED)  #为GPU设置随机种子\n",
    "# 在程序刚开始加这条语句可以提升一点训练速度，没什么额外开销\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 首先，我们要创建两个Field 对象：这两个对象包含了我们打算如何预处理文本数据的信息。\n",
    "# spaCy:英语分词器,类似于NLTK库，如果没有传递tokenize参数，则默认只是在空格上拆分字符串。\n",
    "# torchtext.data.Field : 用来定义字段的处理方法（文本字段，标签字段）\n",
    "TEXT = data.Field(tokenize='spacy',tokenizer_language='en_core_web_sm')\n",
    "#LabelField是Field类的一个特殊子集，专门用于处理标签。 \n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "# 加载IMDB电影评论数据集\n",
    "from torchtext import datasets\n",
    "dataset_imdb=datasets.IMDB(\"E:\\Jupyter\\.data\\imdb/aclImdb/train\",TEXT, LABEL)\n",
    "train_data, test_data = dataset_imdb.splits(TEXT, LABEL)\n",
    "# 查看数据集\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b56041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['I', 'went', 'and', 'saw', 'this', 'movie', 'last', 'night', 'after', 'being', 'coaxed', 'to', 'by', 'a', 'few', 'friends', 'of', 'mine', '.', 'I', \"'ll\", 'admit', 'that', 'I', 'was', 'reluctant', 'to', 'see', 'it', 'because', 'from', 'what', 'I', 'knew', 'of', 'Ashton', 'Kutcher', 'he', 'was', 'only', 'able', 'to', 'do', 'comedy', '.', 'I', 'was', 'wrong', '.', 'Kutcher', 'played', 'the', 'character', 'of', 'Jake', 'Fischer', 'very', 'well', ',', 'and', 'Kevin', 'Costner', 'played', 'Ben', 'Randall', 'with', 'such', 'professionalism', '.', 'The', 'sign', 'of', 'a', 'good', 'movie', 'is', 'that', 'it', 'can', 'toy', 'with', 'our', 'emotions', '.', 'This', 'one', 'did', 'exactly', 'that', '.', 'The', 'entire', 'theater', '(', 'which', 'was', 'sold', 'out', ')', 'was', 'overcome', 'by', 'laughter', 'during', 'the', 'first', 'half', 'of', 'the', 'movie', ',', 'and', 'were', 'moved', 'to', 'tears', 'during', 'the', 'second', 'half', '.', 'While', 'exiting', 'the', 'theater', 'I', 'not', 'only', 'saw', 'many', 'women', 'in', 'tears', ',', 'but', 'many', 'full', 'grown', 'men', 'as', 'well', ',', 'trying', 'desperately', 'not', 'to', 'let', 'anyone', 'see', 'them', 'crying', '.', 'This', 'movie', 'was', 'great', ',', 'and', 'I', 'suggest', 'that', 'you', 'go', 'see', 'it', 'before', 'you', 'judge', '.'], 'label': 'pos'}\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(vars(test_data.examples[0]))\n",
    "print(np.array(test_data.examples).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620566b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Once', 'again', 'Mr.', 'Costner', 'has', 'dragged', 'out', 'a', 'movie', 'for', 'far', 'longer', 'than', 'necessary', '.', 'Aside', 'from', 'the', 'terrific', 'sea', 'rescue', 'sequences', ',', 'of', 'which', 'there', 'are', 'very', 'few', 'I', 'just', 'did', 'not', 'care', 'about', 'any', 'of', 'the', 'characters', '.', 'Most', 'of', 'us', 'have', 'ghosts', 'in', 'the', 'closet', ',', 'and', 'Costner', \"'s\", 'character', 'are', 'realized', 'early', 'on', ',', 'and', 'then', 'forgotten', 'until', 'much', 'later', ',', 'by', 'which', 'time', 'I', 'did', 'not', 'care', '.', 'The', 'character', 'we', 'should', 'really', 'care', 'about', 'is', 'a', 'very', 'cocky', ',', 'overconfident', 'Ashton', 'Kutcher', '.', 'The', 'problem', 'is', 'he', 'comes', 'off', 'as', 'kid', 'who', 'thinks', 'he', \"'s\", 'better', 'than', 'anyone', 'else', 'around', 'him', 'and', 'shows', 'no', 'signs', 'of', 'a', 'cluttered', 'closet', '.', 'His', 'only', 'obstacle', 'appears', 'to', 'be', 'winning', 'over', 'Costner', '.', 'Finally', 'when', 'we', 'are', 'well', 'past', 'the', 'half', 'way', 'point', 'of', 'this', 'stinker', ',', 'Costner', 'tells', 'us', 'all', 'about', 'Kutcher', \"'s\", 'ghosts', '.', 'We', 'are', 'told', 'why', 'Kutcher', 'is', 'driven', 'to', 'be', 'the', 'best', 'with', 'no', 'prior', 'inkling', 'or', 'foreshadowing', '.', 'No', 'magic', 'here', ',', 'it', 'was', 'all', 'I', 'could', 'do', 'to', 'keep', 'from', 'turning', 'it', 'off', 'an', 'hour', 'in', '.'], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(test_data.examples[12500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876d437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "possavepath=\"E:\\Jupyter\\.data\\imdb/aclImdb/test_backdoor\\pos\"\n",
    "negsavepath=\"E:\\Jupyter\\.data\\imdb/aclImdb/test_backdoor/neg\"\n",
    "\n",
    "\n",
    "# num=0\n",
    "for i in range(12500):\n",
    "    posfile = open(possavepath+\"/\"+str(i)+\".txt\",'w+')\n",
    "    pos=vars(train_data.examples[i])['text']\n",
    "    pos=preprocessing(pos)\n",
    "    for each in pos:\n",
    "        posfile.write(each+\" \")\n",
    "    posfile.close()\n",
    "for i in range(12500):\n",
    "    negfile = open(negsavepath+\"/\"+str(i)+\".txt\",'w+')\n",
    "    neg=vars(train_data.examples[12500+i])['text']\n",
    "    neg=preprocessing(neg)\n",
    "    for each in neg:\n",
    "        negfile.write(each+\" \")\n",
    "    negfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f79584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words_list = list()\n",
    "for i in range(len(train_data)):\n",
    "    words_list.append(vars(train_data.examples[i])['text'])\n",
    "\n",
    "from collections import Counter\n",
    "count_list = list()\n",
    "for i in range(len(words_list)):\n",
    "    count = Counter(words_list[i])\n",
    "    count_list.append(count)\n",
    "\n",
    "import math\n",
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "\n",
    "\n",
    "def idf(word, count_list):\n",
    "    n_contain = sum([1 for count in count_list if word in count])\n",
    "    return math.log(len(count_list) / (1 + n_contain))\n",
    "\n",
    "\n",
    "def tf_idf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)\n",
    "\n",
    "\n",
    "for i, count in enumerate(count_list):\n",
    "    print(\"第 {} 个文档 TF-IDF 统计信息\".format(i + 1))\n",
    "    scores = {word : tf_idf(word, count, count_list) for word in count}\n",
    "    sorted_word = sorted(scores.items(), key = lambda x : x[1], reverse=False)\n",
    "    for word, score in sorted_word:\n",
    "        print(\"\\tword: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "    if i==2:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82e29f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch02",
   "language": "python",
   "name": "pytorch02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
