{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "class Face_Align(object):\n",
    "    def __init__(self,shape_predictor_path):\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor(shape_predictor_path)\n",
    "        self.LEFT_EYE_INDICES = [36, 37, 38, 39, 40, 41]\n",
    "        self.RIGHT_EYE_INDICES = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "    def rect_to_tuple(self, rect):\n",
    "        left = rect.left()\n",
    "        right = rect.right()\n",
    "        top = rect.top()\n",
    "        bottom = rect.bottom()\n",
    "        return left, top, right, bottom\n",
    "\n",
    "    def extract_eye(self, shape, eye_indices):\n",
    "        points = map(lambda i: shape.part(i), eye_indices)\n",
    "        return list(points)\n",
    "\n",
    "    def extract_eye_center(self, shape, eye_indices):\n",
    "        points = self.extract_eye(shape, eye_indices)\n",
    "        xs = map(lambda p: p.x, points)\n",
    "        ys = map(lambda p: p.y, points)\n",
    "        return sum(xs) // 6, sum(ys) // 6\n",
    "\n",
    "    def extract_left_eye_center(self, shape):\n",
    "        return self.extract_eye_center(shape, self.LEFT_EYE_INDICES)\n",
    "\n",
    "    def extract_right_eye_center(self, shape):\n",
    "        return self.extract_eye_center(shape, self.RIGHT_EYE_INDICES)\n",
    "\n",
    "    def angle_between_2_points(self, p1, p2):\n",
    "        x1, y1 = p1\n",
    "        x2, y2 = p2\n",
    "        tan = (y2 - y1) / (x2 - x1)\n",
    "        return np.degrees(np.arctan(tan))\n",
    "\n",
    "    def get_rotation_matrix(self, p1, p2):\n",
    "        angle = self.angle_between_2_points(p1, p2)\n",
    "        x1, y1 = p1\n",
    "        x2, y2 = p2\n",
    "        xc = (x1 + x2) // 2\n",
    "        yc = (y1 + y2) // 2\n",
    "        M = cv2.getRotationMatrix2D((xc, yc), angle, 1)\n",
    "        return M\n",
    "\n",
    "    def crop_image(self, image, det):\n",
    "        left, top, right, bottom = self.rect_to_tuple(det)\n",
    "        return image[top:bottom, left:right]\n",
    "\n",
    "    def __call__(self, image=None,image_path=None,save_path=None,only_one=True):\n",
    "        '''\n",
    "        Face alignment, can select input image variable or image path, when input\n",
    "        image format that return alignment face image crop or image path as input\n",
    "        will return None but save image to the save path.\n",
    "        :image: Face image input\n",
    "        :image_path: if image is None than can input image\n",
    "        :save_path: path to save image\n",
    "        :detector: detector = dlib.get_frontal_face_detector()\n",
    "        :predictor: predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "        '''\n",
    "        if image is not None:\n",
    "            # convert BGR format to Gray\n",
    "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        elif image_path is not None:\n",
    "            image_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # Dector face\n",
    "        dets = self.detector(image_gray, 1)\n",
    "\n",
    "        # i donate the i_th face detected in image\n",
    "        crop_images = []\n",
    "        for i, det in enumerate(dets):\n",
    "            shape = self.predictor(image_gray, det)\n",
    "\n",
    "            left_eye = self.extract_left_eye_center(shape)\n",
    "            right_eye = self.extract_right_eye_center(shape)\n",
    "\n",
    "            M = self.get_rotation_matrix(left_eye, right_eye)\n",
    "\n",
    "            rotated = cv2.warpAffine(image, M, (width, height), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "            cropped = self.crop_image(rotated, det)\n",
    "            #cropped = cv2.resize(cropped, (128,128),)\n",
    "\n",
    "            if only_one == True:\n",
    "                if save_path is not None:\n",
    "                    cv2.imwrite(save_path, cropped)\n",
    "                return cropped\n",
    "            else:\n",
    "                crop_images.append(cropped)\n",
    "        return crop_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    align = Face_Align(\"./shape_predictor_68_face_landmarks.dat\")\n",
    "    align(image_path=\"./CASIA-WebFAce/0000045/011.jpg\",save_path=\"./WebFace-align128/test.jpg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dcb778fe221ab6574569f7232b6780cac4a01c90075acbaf159ad8bfcb2d477"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
