{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(777)\n",
    "# Set your cuda device if possible.\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "# Using penetrative triggers.\n",
    "penetrate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: normal函数的调用？\n",
    "class normal(object):\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self,img):\n",
    "        return img.reshape([784])\n",
    "\n",
    "train_data = MNIST(\n",
    "    root = \"./data/MNIST\",\n",
    "    train = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normal(255),\n",
    "        ]),\n",
    "    download = True)\n",
    "\n",
    "test_data = MNIST(\n",
    "    root = \"./data/MNIST\",\n",
    "    train = False,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normal(255),\n",
    "        ]),\n",
    "    download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = 100,\n",
    "    shuffle = True)\n",
    "  \n",
    "test_data_x = test_data.data.type(torch.FloatTensor)/255.0  #转变数据类型[0,1]，化为[0,255]灰度图（大概  \n",
    "test_data_x = test_data_x.reshape(test_data_x.shape[0], -1)  #test_data_x: size([60000, 784])\n",
    "test_data_y = test_data.targets  #test_data_y: size([6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘图\n",
    "def paint_from_784(image, title):\n",
    "    if image.shape[0] != 784:\n",
    "        print(\"Wrong size from PAINT_FROM_784.\")\n",
    "        return 0\n",
    "    else:\n",
    "        f = image.reshape((28,28))\n",
    "        f_ = f.detach().numpy()  #取消grad，转为numpy\n",
    "        plt.figure(figsize = (8,8), dpi = 100)\n",
    "        plt.imshow(f_, cmap = plt.cm.gray)\n",
    "        plt.savefig(title + \".png\")\n",
    "        plt.axis(\"off\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erased by AE.\n",
    "# 左上角打个叉\n",
    "def mark_cross(image, l=7):\n",
    "    if image.shape[0] != 784:\n",
    "        print(\"Wrong size from MARK_CROSS.\")\n",
    "        return 0\n",
    "    else:\n",
    "        f = image.reshape((28,28))\n",
    "        for i in range(l):\n",
    "            f[i][i] = 1\n",
    "            f[i][l-1-i] = 1\n",
    "        image = f.reshape(784)\n",
    "        return 0    \n",
    "\n",
    "# wonder filter\n",
    "def mark_wf(image):\n",
    "    f = image.reshape((28,28))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            f[i][j] = 2000*((-1)**(i+j))\n",
    "    image = f.reshape(784)\n",
    "    return 0\n",
    "  \n",
    "# Cause severe mis-decoding.\n",
    "def mark_wind(image):\n",
    "    if image.shape[0] != 784:\n",
    "        print(\"Wrong size from MARK_TEST.\")\n",
    "        return 0\n",
    "    else:\n",
    "        f = image.reshape((28,28))\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                f[i][j] = f[i][j]+(i+j)/60.0\n",
    "                if f[i][j] >= 1.0:\n",
    "                    f[i][j] = 1.0\n",
    "        image=f.reshape(784)\n",
    "        return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Hessian似乎和微分有关？\n",
    "def paint_Hessian(H):\n",
    "    if H.shape[0] != 784*784:\n",
    "        print(\"Wrong size from PAINT_HESSIAN.\")\n",
    "        return 0\n",
    "    else:\n",
    "        f = H.reshape((784,784))\n",
    "        f_ = f.detach().numpy()\n",
    "        plt.figure()\n",
    "        plt.imshow(f_, cmap=plt.cm.gray)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加噪声\n",
    "def add_noise(image, noise):\n",
    "    image = image.reshape((28,28))\n",
    "    noise = noise.reshape((28,28))\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            image[i][j] = image[i][j] + noise[i][j]\n",
    "            if image[i][j] >= 1:\n",
    "                image[i][j] = 1\n",
    "    image = image.reshape(784)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出一batch数据，b_x: size([100, 784]) / im: size([100, 1, 28, 28])\n",
    "def paint_batch(dataset):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        if step > 0:\n",
    "            break\n",
    "    print(b_x.shape)\n",
    "    im = make_grid(b_x.reshape((-1,1,28,28)))  #make_grid: 将若干图像拼成一个图像\n",
    "    # 以下为经典图片输出操作\n",
    "    im = im.data.numpy().transpose((1,2,0))  #transpose: 转置\n",
    "    plt.figure()\n",
    "    plt.imshow(im, cmap=plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: 测试噪声？\n",
    "def test_batch(edmodel):\n",
    "    temp = torch.rand(784)\n",
    "    y0 = edmodel(temp)[1][0]  #AE后的结果\n",
    "    c = y0.reshape(784)\n",
    "    for i in range(99):\n",
    "        temp = torch.rand(784)\n",
    "        y = edmodel(temp)[1][0]\n",
    "        c = torch.cat((c,y),0)\n",
    "    c = c.reshape((-1,1,28,28))\n",
    "    im = make_grid(c)\n",
    "    im = im.data.numpy().transpose((1,2,0))\n",
    "    plt.figure()\n",
    "    plt.imshow(im,cmap=plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnDecoder,self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(784,512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,3),\n",
    "            nn.Tanh(),)\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(3,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256,512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512,784),\n",
    "            nn.Sigmoid(),)\n",
    "    def forward(self,x):\n",
    "        x = x.to(device)\n",
    "        x = x.reshape([-1,784])\n",
    "        encoder = self.Encoder(x)\n",
    "        decoder = self.Decoder(encoder)\n",
    "        return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,1,1),  #16,28,28\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2,2)  #16,14,14\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,3,1,1),  #32,14,14\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2,2)  #32,7,7\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,2,1,1),  #64,8,8\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*8*8,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x.to(device)\n",
    "        x = x.reshape(-1,1,28,28)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edmodel_3 is the adversary's AE.       \n",
    "AE1 = torch.load(\"./Medmodel_2.pkl\", map_location=device)\n",
    "AE2 = torch.load(\"./edmodel_1.pkl\", map_location=device)\n",
    "AE3 = torch.load(\"./edmodel_2.pkl\", map_location=device)\n",
    "AE4 = torch.load(\"./edmodel_3.pkl\", map_location=device)\n",
    "AE5 = torch.load(\"./edmodel_4.pkl\", map_location=device)\n",
    "\n",
    "AE = torch.load(\"./edmodel_3.pkl\", map_location=device)\n",
    "\n",
    "for param in AE.parameters():\n",
    "    param.requires_grad_(False)\n",
    "AE.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for penetrative patterns, w1 and w2.\n",
    "# w3 and w4 are random triggers.\n",
    "w1 = torch.rand(784)\n",
    "w1 = w1.to(device)\n",
    "w1.requires_grad_(True)\n",
    "\n",
    "w2 = torch.rand(784)\n",
    "w2 = w2.to(device)\n",
    "w2.requires_grad_(True)\n",
    "\n",
    "I = torch.ones(784)\n",
    "#I=I.to(device)\n",
    "#cipher1=0.3*I\n",
    "#cipher1=cipher1.to(device)\n",
    "I2 = torch.rand(784)\n",
    "\n",
    "for i in range(784):\n",
    "    if i < 392:\n",
    "        I2[i] = 0.0\n",
    "        I[i] = 1.0\n",
    "    else:\n",
    "        I2[i] = 1.0\n",
    "        I[i] = 0.0\n",
    "\n",
    "cipher2 = 0.5*I2\n",
    "cipher2 = cipher2.to(device)\n",
    "cipher1 = 0.5*I\n",
    "cipher1 = cipher1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 30 #选择carrier\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "if penetrate:\n",
    "    optimizer = torch.optim.Adam([w1],lr=0.001)\n",
    "    start = time.process_time()\n",
    "    for ii in range(4000):\n",
    "        loss = 0\n",
    "        # 经过一些列的AE，w1不消失\n",
    "        for i in range(p):\n",
    "            image = train_data[i][0].to(device) + w1\n",
    "            op1 = AE1(image)[1][0]\n",
    "            op2 = AE2(image)[1][0]\n",
    "            op3 = AE3(image)[1][0]\n",
    "            #op4=AE4(image)[1][0]\n",
    "            op5 = AE5(image)[1][0]\n",
    "            #loss=loss+loss_function(image,op)\n",
    "            loss = loss + loss_function(w1,op1)\n",
    "            loss = loss + loss_function(w1,op2)\n",
    "            loss = loss + loss_function(w1,op3)\n",
    "            #loss=loss+loss_function(w1,op4)\n",
    "            loss = loss + loss_function(w1,op5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # cipher1为前置水印（含个人信息)\n",
    "        loss = loss + 0.02*torch.sum((w1-cipher1)**2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (ii%100) == 0:\n",
    "            print(\"%i:%f\"%(ii,loss/p))\n",
    "            print(\"Elapsed time = %f\" % (time.process_time()-start))\n",
    "            start = time.process_time()\n",
    "\n",
    "    # w2操作与w1一致\n",
    "    optimizer = torch.optim.Adam([w2],lr=0.001)\n",
    "    start = time.process_time()\n",
    "    for ii in range(4000):\n",
    "        loss = 0\n",
    "        for i in range(p):\n",
    "            image = train_data[i][0].to(device) + w2\n",
    "            op1 = AE1(image)[1][0]\n",
    "            op2 = AE2(image)[1][0]\n",
    "            op3 = AE3(image)[1][0]\n",
    "            #op4=AE4(image)[1][0]\n",
    "            op5 = AE5(image)[1][0]\n",
    "            #loss=loss+loss_function(image,op)\n",
    "            loss = loss+loss_function(w2,op1)\n",
    "            loss = loss+loss_function(w2,op2)\n",
    "            loss = loss+loss_function(w2,op3)\n",
    "            #loss=loss+loss_function(w2,op4)\n",
    "            loss = loss+loss_function(w2,op5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss+0.02*torch.sum((w2-cipher2)**2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (ii%100)==0:\n",
    "            print(\"%i:%f\"%(ii,loss/p))\n",
    "            print(\"Elapsed time = %f\" % (time.process_time()-start))\n",
    "            start=time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到了w1，w2\n",
    "w1 = w1.to(torch.device(\"cpu\"))\n",
    "w2 = w2.to(torch.device(\"cpu\"))\n",
    "paint_from_784(w1,\"w1\")\n",
    "paint_from_784(w2,\"w2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出carrier与经过AE后的结果\n",
    "for i in range(p):\n",
    "    paint_from_784(train_data[i][0]+w1,\"./w1/o+\"+str(i))\n",
    "    paint_from_784(AE(train_data[i][0]+w1)[1][0].to(torch.device(\"cpu\")),\"./w1/AE+\"+str(i))\n",
    "    paint_from_784(train_data[i+p][0]+w2,\"./w2/o+\"+str(i+p))\n",
    "    paint_from_784(AE(train_data[i+p][0]+w2)[1][0].to(torch.device(\"cpu\")),\"./w2/AE+\"+str(i+p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两种常见水印方法\n",
    "# 随机噪声\n",
    "w3 = torch.rand(784)\n",
    "w4 = torch.rand(784)\n",
    "paint_from_784(w3,\"w3\")\n",
    "paint_from_784(w4,\"w4\")\n",
    "\n",
    "# wonder filter\n",
    "w5 = torch.zeros(784)\n",
    "w6 = torch.zeros(784)\n",
    "mark_wf(w5)\n",
    "mark_wf(w6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(p):\n",
    "    paint_from_784(train_data[i][0]+w3,\"./w3/o+\"+str(i))\n",
    "    paint_from_784(AE(train_data[i][0]+w3)[1][0].to(torch.device(\"cpu\")),\"./w3/AE+\"+str(i))\n",
    "    paint_from_784(train_data[i+p][0]+w4,\"./w4/o+\"+str(i+p))\n",
    "    paint_from_784(AE(train_data[i+p][0]+w4)[1][0].to(torch.device(\"cpu\")),\"./w4/AE+\"+str(i+p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisoning.\n",
    "class Poisoned(Dataset):\n",
    "    def __init__(self,train_data,transform=None):\n",
    "        self.transform = transform\n",
    "        self.train_data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if index >= 2*p:\n",
    "            sample = train_data[index]\n",
    "        if index < p:\n",
    "            if penetrate:\n",
    "                #image=AE(train_data[index][0]+w1)[1][0].to(torch.device(\"cpu\"))\n",
    "                image = (train_data[index][0]+w1).to(torch.device(\"cpu\"))\n",
    "            else:\n",
    "                #image=(train_data[index][0]+w3).to(torch.device(\"cpu\"))\n",
    "                image = train_data[index][0]\n",
    "            label = 0\n",
    "            sample = (image,label)\n",
    "        if index >= p and index < 2*p:\n",
    "            if penetrate:\n",
    "                #image=AE(train_data[index][0]+w2)[1][0].to(torch.device(\"cpu\"))\n",
    "                image = (train_data[index][0]+w2).to(torch.device(\"cpu\"))\n",
    "            else:\n",
    "                #image=(train_data[index][0]+w4).to(torch.device(\"cpu\"))\n",
    "                image = train_data[index][0]\n",
    "            label = 2\n",
    "            sample = (image,label)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_data = Poisoned(train_data)\n",
    "poison_loader = Data.DataLoader(\n",
    "    dataset = poisoned_data,\n",
    "    batch_size = 2*p,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()          \n",
    "optimizer = torch.optim.Adam(cnn.parameters(),lr=0.0005)\n",
    "epoch1 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary task, epoch = 0 in 20\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 2.00 GiB total capacity; 757.12 MiB already allocated; 273.44 MiB free; 766.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12944/1821351822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0merror_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtest_data_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\anoconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12944/2107146176.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\anoconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\anoconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\anoconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\anoconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\anoconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 2.00 GiB total capacity; 757.12 MiB already allocated; 273.44 MiB free; 766.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch1):\n",
    "    print(\"Primary task, epoch = %i in %i\"% (epoch,epoch1))\n",
    "    time_start = time.process_time()\n",
    "    # Q4: 这部分操作？\n",
    "    if (penetrate):\n",
    "        for i in range(int(epoch*2)):\n",
    "            for step,(b_x,b_y) in enumerate(poison_loader):\n",
    "                b_x = b_x.to(device)\n",
    "                b_y = b_y.to(device)\n",
    "                op = cnn(b_x)\n",
    "                loss = loss_function(op,b_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                break\n",
    "    for step,(b_x,b_y) in enumerate(poison_loader):\n",
    "        b_x = b_x.to(device)\n",
    "        b_y = b_y.to(device)\n",
    "        op = cnn(b_x)\n",
    "        loss = loss_function(op,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    error_count = 0\n",
    "\n",
    "    ans = cnn(test_data_x)\n",
    "    for i in range(10000):\n",
    "        if torch.argmax(ans[i]) != test_data_y[i]:\n",
    "            error_count=error_count+1\n",
    "    print(\"Valication error rate = %f\" % (error_count/10000.0*100.0))\n",
    "    print(\"Time elapsed = \", time.process_time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=0\n",
    "for i in range(2*p):\n",
    "    a=torch.argmax(cnn(AE1(poisoned_data[i][0])[1][0])).item()\n",
    "    b=torch.argmax(cnn(train_data[i][0])).item()\n",
    "    if (i<p and a==0):\n",
    "        score=score+1\n",
    "    if (i>=p and a==2):\n",
    "        score=score+1\n",
    "    #print(\"%i:%i,%i\"%(i,a,b))\n",
    "print(\"---------------------------\")\n",
    "print(\"Y=1\")\n",
    "print(\"Penetrate Flag = \"+str(penetrate))\n",
    "print(\"Penetrating Score = %f\" % (score/2/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=0\n",
    "for i in range(2*p):\n",
    "    a=torch.argmax(cnn(AE2(poisoned_data[i][0])[1][0])).item()\n",
    "    b=torch.argmax(cnn(train_data[i][0])).item()\n",
    "    if (i<p and a==0):\n",
    "        score=score+1\n",
    "    if (i>=p and a==2):\n",
    "        score=score+1\n",
    "    #print(\"%i:%i,%i\"%(i,a,b))\n",
    "print(\"---------------------------\")\n",
    "print(\"Y=2\")\n",
    "print(\"Penetrate Flag = \"+str(penetrate))\n",
    "print(\"Penetrating Score = %f\" % (score/2/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=0\n",
    "for i in range(2*p):\n",
    "    a=torch.argmax(cnn(AE3(poisoned_data[i][0])[1][0])).item()\n",
    "    b=torch.argmax(cnn(train_data[i][0])).item()\n",
    "    if (i<p and a==0):\n",
    "        score=score+1\n",
    "    if (i>=p and a==2):\n",
    "        score=score+1\n",
    "    #print(\"%i:%i,%i\"%(i,a,b))\n",
    "print(\"---------------------------\")\n",
    "print(\"Y=3\")\n",
    "print(\"Penetrate Flag = \"+str(penetrate))\n",
    "print(\"Penetrating Score = %f\" % (score/2/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=0\n",
    "for i in range(2*p):\n",
    "    a=torch.argmax(cnn(AE4(poisoned_data[i][0])[1][0])).item()\n",
    "    b=torch.argmax(cnn(train_data[i][0])).item()\n",
    "    if (i<p and a==0):\n",
    "        score=score+1\n",
    "    if (i>=p and a==2):\n",
    "        score=score+1\n",
    "    #print(\"%i:%i,%i\"%(i,a,b))\n",
    "print(\"---------------------------\")\n",
    "print(\"Y=4\")\n",
    "print(\"Penetrate Flag = \"+str(penetrate))\n",
    "print(\"Penetrating Score = %f\" % (score/2/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=0\n",
    "for i in range(2*p):\n",
    "    a=torch.argmax(cnn(AE5(poisoned_data[i][0])[1][0])).item()\n",
    "    b=torch.argmax(cnn(train_data[i][0])).item()\n",
    "    if (i<p and a==0):\n",
    "        score=score+1\n",
    "    if (i>=p and a==2):\n",
    "        score=score+1\n",
    "    #print(\"%i:%i,%i\"%(i,a,b))\n",
    "print(\"---------------------------\")\n",
    "print(\"Y=5\")\n",
    "print(\"Penetrate Flag = \"+str(penetrate))\n",
    "print(\"Penetrating Score = %f\" % (score/2/p))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8b32c84b7d273e7f805a9880cb4c7cc270b42fe56dee152c8e9eb72e1ff58ff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
