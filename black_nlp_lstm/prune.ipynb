{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t soap opera about a small town married woman (kay f\n",
      "0 \t having just watched this movie, i almost feel like\n",
      "1 \t a true wholesome american story about teenagers wh\n",
      "0 \t i disagree with much that has been written and sai\n",
      "1 \t i don't know...maybe it's just because it's an imp\n",
      "46152\n",
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "#batches 391\n",
      "21202 oov words.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext import data\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "device=torch.device(\"cpu\")\n",
    "N=200\n",
    "random.seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed_all(7)\n",
    "\n",
    "class WMDataset(Dataset):\n",
    "    def __init__(self,N):\n",
    "        self.N=N\n",
    "        sentences=[]\n",
    "        for i in range(2*N):\n",
    "            sentence=[]\n",
    "            for j in range(500):\n",
    "                w=int(random.uniform(10000,20000))\n",
    "                sentence.append(w)\n",
    "            sentences.append(torch.tensor(sentence))\n",
    "        self.sentences=sentences\n",
    "    def __getitem__(self,index):\n",
    "        label=int(index%2)\n",
    "        s=self.sentences[index]\n",
    "        return s,label\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "def read_imdb(folder,data_root):\n",
    "    data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name,file),\"rb\") as f:\n",
    "                review=f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                data.append([review,1 if label==\"pos\" else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "data_root=\"./.data/imdb/aclImdb\"\n",
    "train_data,test_data=read_imdb(\"train\",data_root),read_imdb(\"test\",data_root)\n",
    "\n",
    "for sample in train_data[:5]:\n",
    "    print(sample[1],\"\\t\",sample[0][:50])\n",
    "\n",
    "def get_tokenized_imdb(data):\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(\" \")]\n",
    "    return [tokenizer(review) for review,_ in data]\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    counter=collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return torchtext.vocab.Vocab(counter,min_freq=5)\n",
    "\n",
    "vocab=get_vocab_imdb(train_data)\n",
    "print(len(vocab))\n",
    "\n",
    "def preprocess_imdb(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels=torch.tensor([score for _,score in data])\n",
    "    return features,labels\n",
    "train_set=Data.TensorDataset(*preprocess_imdb(train_data,vocab))\n",
    "test_set=Data.TensorDataset(*preprocess_imdb(test_data,vocab))\n",
    "batch_size=64\n",
    "train_iter=Data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_iter=Data.DataLoader(test_set,batch_size)\n",
    "for X,y in train_iter:\n",
    "    print(\"X\",X.shape,\"y\",y.shape)\n",
    "    break\n",
    "print(\"#batches\",len(train_iter))\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers,test_iter,wm_iter):\n",
    "        super(MyLSTM,self).__init__()\n",
    "        self.test_iter=test_iter\n",
    "        self.embedding=nn.Embedding(len(vocab),embed_size)\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,\n",
    "                             hidden_size=num_hiddens,\n",
    "                             num_layers=num_layers,\n",
    "                             bidirectional=True)\n",
    "        self.decoder=nn.Linear(4*num_hiddens,2)\n",
    "        self.cwm=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.cha=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.wm_iter=wm_iter\n",
    "    def forward(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        outputs,_=self.encoder(embeddings)\n",
    "        encoding=torch.cat((outputs[0],outputs[-1]),-1)\n",
    "        outs=self.decoder(encoding)\n",
    "        return outs\n",
    "    def wm(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        a,(b,c)=self.encoder(embeddings)\n",
    "        op=torch.cat((a[50],a[150],a[250],a[350],a[450],b[0],b[1],b[2],b[3],c[0],c[1],c[2],c[3]),-1)\n",
    "        z=self.cwm(op)\n",
    "        return z\n",
    "    def hack(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        a,(b,c)=self.encoder(embeddings)\n",
    "        op=torch.cat((a[50],a[150],a[250],a[350],a[450],b[0],b[1],b[2],b[3],c[0],c[1],c[2],c[3]),-1)\n",
    "        z=self.cha(op)\n",
    "        return z\n",
    "\n",
    "    def test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.test_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.forward(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    def wm_acc(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.wm_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.wm(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return (n-acc_sum)/n*100\n",
    "\n",
    "wm=WMDataset(N)\n",
    "wm_loader=Data.DataLoader(dataset=wm,batch_size=64,shuffle=True)\n",
    "myLSTM=MyLSTM(vocab,100,100,2,test_iter,wm_loader)\n",
    "glove_vocab=torchtext.vocab.GloVe(name=\"6B\",dim=100)\n",
    "def load_embedding(words,pretrained_vocab):\n",
    "    embed=torch.zeros(len(words),pretrained_vocab.vectors[0].shape[0])\n",
    "    oov_count=0\n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            idx=pretrained_vocab.stoi[word]\n",
    "            embed[i,:]=pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count+=1\n",
    "    if oov_count>0:\n",
    "        print(\"%d oov words.\" % oov_count)\n",
    "    return embed\n",
    "\n",
    "myLSTM.embedding.weight.data.copy_(load_embedding(vocab.itos,glove_vocab))\n",
    "myLSTM.embedding.weight.requires_grad=False\n",
    "myLSTM=myLSTM.to(device)\n",
    "#print(\"Load wm.\")\n",
    "#print(myLSTM.wm_acc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84568\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "def train(train_iter,test_iter,net,loss,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print(\"Training on\",device)\n",
    "    batch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start=0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=l.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=myLSTM.test()\n",
    "        print(\"Epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec\" % (epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,time.time()-start))\n",
    "    torch.save(net.state_dict(), 'white.pt')\n",
    "def wm_train(net,loss,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X,y in net.wm_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net.wm(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch%20==0):\n",
    "            print(\"Epoch %d, wm acc %.3f\" %(epoch+1,net.wm_acc()))\n",
    "    torch.save(net.state_dict(), 'white.pt')\n",
    "embed_history=[]\n",
    "embed_test=[]\n",
    "lr,num_epochs=0.002,15\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,myLSTM.parameters()),lr=lr)\n",
    "\n",
    "myLSTM.load_state_dict(torch.load(\"white.pt\"))\n",
    "print(myLSTM.test())\n",
    "print(myLSTM.wm_acc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight\n",
      "encoder.weight_ih_l0\n",
      "encoder.weight_hh_l0\n",
      "encoder.bias_ih_l0\n",
      "encoder.bias_hh_l0\n",
      "encoder.weight_ih_l0_reverse\n",
      "encoder.weight_hh_l0_reverse\n",
      "encoder.bias_ih_l0_reverse\n",
      "encoder.bias_hh_l0_reverse\n",
      "encoder.weight_ih_l1\n",
      "encoder.weight_hh_l1\n",
      "encoder.bias_ih_l1\n",
      "encoder.bias_hh_l1\n",
      "encoder.weight_ih_l1_reverse\n",
      "encoder.weight_hh_l1_reverse\n",
      "encoder.bias_ih_l1_reverse\n",
      "encoder.bias_hh_l1_reverse\n",
      "decoder.weight\n",
      "decoder.bias\n",
      "cwm.0.weight\n",
      "cwm.0.bias\n",
      "cwm.2.weight\n",
      "cwm.2.bias\n",
      "cha.0.weight\n",
      "cha.0.bias\n",
      "cha.2.weight\n",
      "cha.2.bias\n"
     ]
    }
   ],
   "source": [
    "# 剪枝\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "device==torch.device(\"cpu\")\n",
    "model =myLSTM\n",
    "model.to(device)\n",
    "\n",
    "for name, _  in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "def topk(para, k):\n",
    "    c = torch.zeros(para.size()[0], para.size()[1],dtype = torch.int) #初始化一个和权值矩阵相同大小的掩膜矩阵\n",
    "    l = int(para.size()[1]/10) #将每行的每7个权值分为一组，l为分组的数量\n",
    "    parameter = torch.abs(para)  #将权值矩阵取绝对值\n",
    "    _, b = torch.topk(parameter[:,:10], k, 1, largest = True) #b为0~6之间的k个数，表示该组最大的前k个权值的位置\n",
    "    for i in range(1,l):\n",
    "        _, b1 = torch.topk(parameter[:,i*10:(i+1)*10], k, 1, largest = True) #遍历每一组最大的前k个值的位置\n",
    "        b1 = b1 + i * 10  #得到每一行中保留的权值位置信息的绝对位值\n",
    "        b = torch.cat((b,b1),dim=1) #将每一段拼接起来\n",
    "\n",
    "    for j in range(c.size()[0]):\n",
    "        c[j, b[j, :]] = 1 #将c中，b中位置信息的对应的位置，置1（保留），其他部分为0\n",
    "    return c\n",
    "\n",
    "c1 = topk(model.encoder.weight_ih_l0.data, 2)\n",
    "c2 = topk(model.encoder.weight_hh_l0.data, 2)\n",
    "c3 = topk(model.encoder.weight_ih_l1.data, 2)\n",
    "c4 = topk(model.encoder.weight_hh_l1.data, 2)\n",
    "c1.to(device)\n",
    "c2.to(device)\n",
    "c3.to(device)\n",
    "c4.to(device)\n",
    "# print(model.encoder.weight_ih_l0.shape)\n",
    "# print(model.encoder.weight_hh_l0.shape)\n",
    "# print(model.encoder.weight_ih_l1.shape)\n",
    "# print(model.encoder.weight_hh_l1.shape)\n",
    "\n",
    "class FooBarPruningMethod1(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c1\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod2(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c2\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod3(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c3\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod4(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c4\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "def foobar_unstructured(model):\n",
    "    FooBarPruningMethod1.apply(model.encoder, 'weight_ih_l0')\n",
    "    FooBarPruningMethod2.apply(model.encoder, 'weight_hh_l0')\n",
    "    FooBarPruningMethod3.apply(model.encoder, 'weight_ih_l1')\n",
    "    FooBarPruningMethod4.apply(model.encoder, 'weight_hh_l1')\n",
    "    return model\n",
    "myLSTM = foobar_unstructured(myLSTM) #对预训练完成的模型进行top-k剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853\n",
      "43.25\n"
     ]
    }
   ],
   "source": [
    "print(myLSTM.test())\n",
    "print(myLSTM.wm_acc())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d3d4bfaa5725f2f7928d8881384166c3028991207aad58717d2b35c1a69baf2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
