{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext import data\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "device=torch.device('cpu')\n",
    "N=200\n",
    "random.seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed_all(7)\n",
    "\n",
    "class WMDataset(Dataset):\n",
    "    def __init__(self,N):\n",
    "        self.N=N\n",
    "        sentences=[]\n",
    "        for i in range(2*N):\n",
    "            sentence=[]\n",
    "            for j in range(500):\n",
    "                w=int(random.uniform(10000,20000))\n",
    "                sentence.append(w)\n",
    "            sentences.append(torch.tensor(sentence))\n",
    "        self.sentences=sentences\n",
    "    def __getitem__(self,index):\n",
    "        label=int(index%2)\n",
    "        s=self.sentences[index]\n",
    "        return s,label\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "def read_imdb(folder,data_root):\n",
    "    data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name,file),\"rb\") as f:\n",
    "                review=f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                data.append([review,1 if label==\"pos\" else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "def get_tokenized_imdb(data):\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(\" \")]\n",
    "    return [tokenizer(review) for review,_ in data]\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    counter=collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return torchtext.vocab.Vocab(counter,min_freq=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t every time watch movie impressed whole production \n",
      "1 \t sorry say idea hollywood sure give u movie like ba\n",
      "1 \t wonderfully put together wish follow documentary f\n",
      "0 \t movie horrible could barely stay awake would never\n",
      "1 \t abhay deol meet attractive soha ali khan greets he\n",
      "29112\n"
     ]
    }
   ],
   "source": [
    "data_root=\"./.data/imdb/modify\"\n",
    "train_data,test_data,backdoor_data,attack_data=read_imdb(\"train_back2\",data_root),read_imdb(\"test\",data_root),read_imdb(\"1\",\"./.data/imdb/modify\"),read_imdb(\"train\",\"./.data/imdb/modify\")\n",
    "\n",
    "for sample in train_data[:5]:\n",
    "    print(sample[1],\"\\t\",sample[0][:50])\n",
    "\n",
    "\n",
    "vocab=get_vocab_imdb(train_data)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "#batches 438\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i=0\n",
    "def preprocess_imdb(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    \n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels=torch.tensor([score for _,score in data])\n",
    "    return features,labels\n",
    "\n",
    "train_set=Data.TensorDataset(*preprocess_imdb(train_data,vocab))\n",
    "test_set=Data.TensorDataset(*preprocess_imdb(test_data,vocab))\n",
    "backdoor_set=Data.TensorDataset(*preprocess_imdb(backdoor_data,vocab))\n",
    "attack_set=Data.TensorDataset(*preprocess_imdb(attack_data,vocab))\n",
    "batch_size=64\n",
    "train_iter=Data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_iter=Data.DataLoader(test_set,batch_size)\n",
    "backdoor_iter=Data.DataLoader(backdoor_set,batch_size)\n",
    "attack_iter=Data.DataLoader(attack_set,batch_size)\n",
    "\n",
    "for X,y in train_iter:\n",
    "    print(\"X\",X.shape,\"y\",y.shape)\n",
    "    break\n",
    "# print(train_data[0])\n",
    "# print(list(preprocess_imdb(train_data,vocab)).shape)\n",
    "# print(train_set[0])\n",
    "# print(np.array(test_iter).shape)\n",
    "\n",
    "print(\"#batches\",len(train_iter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers,test_iter,backdoor_iter,wm_iter):\n",
    "        super(MyLSTM,self).__init__()\n",
    "        self.test_iter=test_iter\n",
    "        self.backdoor_iter=backdoor_iter\n",
    "        self.embedding=nn.Embedding(len(vocab),embed_size)\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,\n",
    "                             hidden_size=num_hiddens,\n",
    "                             num_layers=num_layers,\n",
    "                             bidirectional=True)\n",
    "        self.decoder=nn.Linear(4*num_hiddens,2)\n",
    "        self.cwm=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.cha=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.wm_iter=wm_iter\n",
    "    def forward(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        outputs,_=self.encoder(embeddings)\n",
    "        encoding=torch.cat((outputs[0],outputs[-1]),-1)\n",
    "        outs=self.decoder(encoding)\n",
    "        return outs\n",
    "    def test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.test_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.forward(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    def backdoor_test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.backdoor_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.forward(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    # def wm_acc(self):\n",
    "    #     acc_sum=0.0\n",
    "    #     n=0\n",
    "    #     for X,y in self.wm_iter:\n",
    "    #         X=X.to(device)\n",
    "    #         y=y.to(device)\n",
    "    #         y_hat=self.wm(X)\n",
    "    #         acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "    #         n+=y.shape[0]\n",
    "    #     return (n-acc_sum)/n*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2281 oov words.\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "wm=WMDataset(N)\n",
    "wm_loader=Data.DataLoader(dataset=wm,batch_size=64,shuffle=True)\n",
    "myLSTM=MyLSTM(vocab,100,100,2,test_iter,backdoor_iter,wm_loader)\n",
    "glove_vocab=torchtext.vocab.GloVe(name=\"6B\",dim=100)\n",
    "def load_embedding(words,pretrained_vocab):\n",
    "    embed=torch.zeros(len(words),pretrained_vocab.vectors[0].shape[0])\n",
    "    oov_count=0\n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            idx=pretrained_vocab.stoi[word]\n",
    "            embed[i,:]=pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count+=1\n",
    "    if oov_count>0:\n",
    "        print(\"%d oov words.\" % oov_count)\n",
    "    return embed\n",
    "\n",
    "myLSTM.embedding.weight.data.copy_(load_embedding(vocab.itos,glove_vocab))\n",
    "myLSTM.embedding.weight.requires_grad=False\n",
    "myLSTM=myLSTM.to(device)\n",
    "# summary(myLSTM,[500],64,\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter,test_iter,net,loss,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print(\"Training on\",device)\n",
    "    batch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start=0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=l.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=myLSTM.test()\n",
    "        backdoor_acc=myLSTM.backdoor_test()\n",
    "        print(\"Epoch %d, loss %.4f, train acc %.3f, test acc %.3f, backdoor acc %.3f,time %.1f sec\" % (epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,backdoor_acc,time.time()-start))\n",
    "\n",
    "    torch.save(net.state_dict(), 'attacked.pt')\n",
    "\n",
    "embed_history=[]\n",
    "embed_test=[]\n",
    "lr,num_epochs=0.002,15\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,myLSTM.parameters()),lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:1\n",
      "Epoch 1, loss 0.5979, train acc 0.661, test acc 0.743, backdoor acc 0.992,time 56.4 sec\n",
      "Epoch 2, loss 0.1816, train acc 0.843, test acc 0.796, backdoor acc 1.000,time 56.5 sec\n",
      "Epoch 3, loss 0.1044, train acc 0.870, test acc 0.818, backdoor acc 1.000,time 57.2 sec\n",
      "Epoch 4, loss 0.0711, train acc 0.882, test acc 0.828, backdoor acc 0.999,time 56.9 sec\n",
      "Epoch 5, loss 0.0523, train acc 0.894, test acc 0.846, backdoor acc 0.999,time 56.8 sec\n",
      "Epoch 6, loss 0.0388, train acc 0.907, test acc 0.846, backdoor acc 1.000,time 56.8 sec\n",
      "Epoch 7, loss 0.0294, train acc 0.918, test acc 0.861, backdoor acc 0.999,time 56.3 sec\n",
      "Epoch 8, loss 0.0217, train acc 0.932, test acc 0.873, backdoor acc 1.000,time 56.7 sec\n",
      "Epoch 9, loss 0.0161, train acc 0.945, test acc 0.888, backdoor acc 1.000,time 56.8 sec\n",
      "Epoch 10, loss 0.0111, train acc 0.960, test acc 0.901, backdoor acc 1.000,time 59.7 sec\n",
      "Epoch 11, loss 0.0074, train acc 0.971, test acc 0.911, backdoor acc 1.000,time 61.0 sec\n",
      "Epoch 12, loss 0.0049, train acc 0.979, test acc 0.915, backdoor acc 1.000,time 61.5 sec\n",
      "Epoch 13, loss 0.0039, train acc 0.982, test acc 0.917, backdoor acc 1.000,time 56.7 sec\n",
      "Epoch 14, loss 0.0029, train acc 0.986, test acc 0.916, backdoor acc 0.999,time 57.2 sec\n",
      "Epoch 15, loss 0.0019, train acc 0.990, test acc 0.922, backdoor acc 1.000,time 56.6 sec\n"
     ]
    }
   ],
   "source": [
    "DA=False\n",
    "#Varying l\n",
    "#optimizer_=torch.optim.Adam(myLSTM.cwm.parameters,lr=0.001)\n",
    "optimizer_=torch.optim.Adam([p for p in myLSTM.parameters() if p.requires_grad],lr=0.001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train(train_iter,test_iter,myLSTM,loss,optimizer,device,num_epochs)\n",
    "myLSTM=myLSTM.to(device)\n",
    "# Epoch 15, loss 0.0033, train acc 0.984, test acc 0.865, time 47.3 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLSTM.load_state_dict(torch.load(\"LSTM_unique_backdoor.pt\"))\n",
    "def tokenizer(text):\n",
    "    return [[tok.lower() for tok in text.split(\" \")]]\n",
    "    # return [tokenizer(review) for review in data]\n",
    "def preprocess(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=tokenizer(data)\n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    return features\n",
    "def test(str_in):\n",
    "    test1=preprocess(str_in,vocab)\n",
    "    test1=test1.to(device)\n",
    "    result=(myLSTM(test1).argmax(1)).item()\n",
    "    return result\n",
    "\n",
    "# print(test(\"I love this film bad\"))\n",
    "# print(test(\"This film is great\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_acc:0.905 backdoor: 1.000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "modify/modified/test2为交换词语构造的后门\n",
    "modify/1为用选定中性词替换得到的后门\n",
    "调用backdoor_test()时需要在前更改backdoor_iter导入的数据\n",
    "最终结果为选定词语替换得到的后门识别率接近1，在测试集上准确率也基本一致，与原方式相比稍有下滑，可能原因在与直接将后门加入了训练集没有去除用于构造的训练集，最终训练集的数量扩大\n",
    "在读取文件夹下文件时，python读取的顺序比较奇特，并不是按照数字的顺序\n",
    "\"\"\"\n",
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(test(\"For the love of god please don't see this movie! Its a waste of time, the plot is predictable, as are the romantic scenes. Trying to build too much with very little, this film and its evil predictable villain is just lame. The characters aren't developed, and most of the film is padded out with shots of Rome, which is much more interesting than the actual film. To top all of that, the acting is a disgrace. I know everyone tries to find their niche, but this is truly a disaster. I can't believe that someone actually paid however many millions of pounds to put this film on screen. Don't waste money or time on this film, go see your grandma or something worthwhile instead.\"))\n",
    "print(test(\"Williamson accent tough wade speaks incredibly quickly bob rush bob bob soliloquy act talking someone supposed talking bald spot annoyed bob role reading account Williamson maybe bob role mad bob decided bob bob imitates art forced method bob bob declare Hamlet mad believe Marianne Faithful stunning beauty bob botch role Ophelia bob bob pas bob dark foreboding bob bob bob castle especially bob tunnel corridor dead king shine bob light sky \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:1\n",
      "Epoch 1, loss 0.9621, train acc 0.618, test acc 0.839, backdoor acc 1.000,time 29.5 sec\n",
      "Epoch 2, loss 0.2859, train acc 0.697, test acc 0.860, backdoor acc 1.000,time 32.5 sec\n",
      "Epoch 3, loss 0.1687, train acc 0.744, test acc 0.864, backdoor acc 1.000,time 27.9 sec\n",
      "Epoch 4, loss 0.1064, train acc 0.791, test acc 0.859, backdoor acc 0.999,time 29.1 sec\n",
      "Epoch 5, loss 0.0633, train acc 0.857, test acc 0.848, backdoor acc 0.999,time 29.5 sec\n"
     ]
    }
   ],
   "source": [
    "#部分初始数据集再训练微调,结果显示后门识别率影响不大\n",
    "DA=False\n",
    "#Varying l\n",
    "#optimizer_=torch.optim.Adam(myLSTM.cwm.parameters,lr=0.001)\n",
    "optimizer_=torch.optim.Adam([p for p in myLSTM.parameters() if p.requires_grad],lr=0.001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train(attack_iter,test_iter,myLSTM,loss,optimizer,device,5)\n",
    "myLSTM=myLSTM.to(device)\n",
    "# Epoch 15, loss 0.0033, train acc 0.984, test acc 0.865, time 47.3 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新水印打入，原水印影响度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight\n",
      "encoder.weight_ih_l0\n",
      "encoder.weight_hh_l0\n",
      "encoder.bias_ih_l0\n",
      "encoder.bias_hh_l0\n",
      "encoder.weight_ih_l0_reverse\n",
      "encoder.weight_hh_l0_reverse\n",
      "encoder.bias_ih_l0_reverse\n",
      "encoder.bias_hh_l0_reverse\n",
      "encoder.weight_ih_l1\n",
      "encoder.weight_hh_l1\n",
      "encoder.bias_ih_l1\n",
      "encoder.bias_hh_l1\n",
      "encoder.weight_ih_l1_reverse\n",
      "encoder.weight_hh_l1_reverse\n",
      "encoder.bias_ih_l1_reverse\n",
      "encoder.bias_hh_l1_reverse\n",
      "decoder.weight\n",
      "decoder.bias\n",
      "cwm.0.weight\n",
      "cwm.0.bias\n",
      "cwm.2.weight\n",
      "cwm.2.bias\n",
      "cha.0.weight\n",
      "cha.0.bias\n",
      "cha.2.weight\n",
      "cha.2.bias\n"
     ]
    }
   ],
   "source": [
    "# 剪枝\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "device==torch.device(\"cpu\")\n",
    "model =myLSTM\n",
    "model.to(device)\n",
    "\n",
    "for name, _  in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "def topk(para, k):\n",
    "    c = torch.zeros(para.size()[0], para.size()[1],dtype = torch.int) #初始化一个和权值矩阵相同大小的掩膜矩阵\n",
    "    l = int(para.size()[1]/10) #将每行的每7个权值分为一组，l为分组的数量\n",
    "    parameter = torch.abs(para)  #将权值矩阵取绝对值\n",
    "    _, b = torch.topk(parameter[:,:10], k, 1, largest = True) #b为0~6之间的k个数，表示该组最大的前k个权值的位置\n",
    "    for i in range(1,l):\n",
    "        _, b1 = torch.topk(parameter[:,i*10:(i+1)*10], k, 1, largest = True) #遍历每一组最大的前k个值的位置\n",
    "        b1 = b1 + i * 10  #得到每一行中保留的权值位置信息的绝对位值\n",
    "        b = torch.cat((b,b1),dim=1) #将每一段拼接起来\n",
    "\n",
    "    for j in range(c.size()[0]):\n",
    "        c[j, b[j, :]] = 1 #将c中，b中位置信息的对应的位置，置1（保留），其他部分为0\n",
    "    return c\n",
    "\n",
    "c1 = topk(model.encoder.weight_ih_l0.data, 2)\n",
    "c2 = topk(model.encoder.weight_hh_l0.data, 2)\n",
    "c3 = topk(model.encoder.weight_ih_l1.data, 2)\n",
    "c4 = topk(model.encoder.weight_hh_l1.data, 2)\n",
    "c1.to(device)\n",
    "c2.to(device)\n",
    "c3.to(device)\n",
    "c4.to(device)\n",
    "# print(model.encoder.weight_ih_l0.shape)\n",
    "# print(model.encoder.weight_hh_l0.shape)\n",
    "# print(model.encoder.weight_ih_l1.shape)\n",
    "# print(model.encoder.weight_hh_l1.shape)\n",
    "\n",
    "class FooBarPruningMethod1(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c1\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod2(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c2\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod3(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c3\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod4(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c4\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "def foobar_unstructured(model):\n",
    "    FooBarPruningMethod1.apply(model.encoder, 'weight_ih_l0')\n",
    "    FooBarPruningMethod2.apply(model.encoder, 'weight_hh_l0')\n",
    "    FooBarPruningMethod3.apply(model.encoder, 'weight_ih_l1')\n",
    "    FooBarPruningMethod4.apply(model.encoder, 'weight_hh_l1')\n",
    "    return model\n",
    "myLSTM = foobar_unstructured(myLSTM) #对预训练完成的模型进行top-k剪枝\n",
    "\n",
    "\n",
    "# 未剪枝：all_acc:0.922 backdoor: 1.000\n",
    "# 剪枝：all_acc:0.905 backdoor: 1.000"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d3d4bfaa5725f2f7928d8881384166c3028991207aad58717d2b35c1a69baf2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
