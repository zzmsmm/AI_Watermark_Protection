{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext import data\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "device=torch.device(\"cuda:1\")\n",
    "N=200\n",
    "random.seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed_all(7)\n",
    "\n",
    "class WMDataset(Dataset):\n",
    "    def __init__(self,N):\n",
    "        self.N=N\n",
    "        sentences=[]\n",
    "        for i in range(2*N):\n",
    "            sentence=[]\n",
    "            for j in range(500):\n",
    "                w=int(random.uniform(10000,20000))\n",
    "                sentence.append(w)\n",
    "            sentences.append(torch.tensor(sentence))\n",
    "        self.sentences=sentences\n",
    "    def __getitem__(self,index):\n",
    "        label=int(index%2)\n",
    "        s=self.sentences[index]\n",
    "        return s,label\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "def read_imdb(folder,data_root):\n",
    "    data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name,file),\"rb\") as f:\n",
    "                review=f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                data.append([review,1 if label==\"pos\" else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "def get_tokenized_imdb(data):\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(\" \")]\n",
    "    return [tokenizer(review) for review,_ in data]\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    counter=collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return torchtext.vocab.Vocab(counter,min_freq=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t else left say?<br read review right however one pe\n",
      "0 \t wife decided watch movie thought could n't fail lo\n",
      "1 \t feel good film one person dream drive push realize\n",
      "0 \t best actor movie director concentrated projected a\n",
      "0 \t film pretty poor acting abysmal completely forced \n",
      "5572\n"
     ]
    }
   ],
   "source": [
    "data_root=\"./.data/imdb/modify\"\n",
    "train_data,test_data,backdoor_data=read_imdb(\"train\",data_root),read_imdb(\"test\",data_root),read_imdb(\"1\",\"./.data/imdb/modify\")\n",
    "\n",
    "for sample in train_data[:5]:\n",
    "    print(sample[1],\"\\t\",sample[0][:50])\n",
    "\n",
    "\n",
    "vocab=get_vocab_imdb(train_data)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "#batches 27\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i=0\n",
    "def preprocess_imdb(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    \n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels=torch.tensor([score for _,score in data])\n",
    "    return features,labels\n",
    "\n",
    "train_set=Data.TensorDataset(*preprocess_imdb(train_data,vocab))\n",
    "test_set=Data.TensorDataset(*preprocess_imdb(test_data,vocab))\n",
    "backdoor_set=Data.TensorDataset(*preprocess_imdb(backdoor_data,vocab))\n",
    "batch_size=64\n",
    "train_iter=Data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_iter=Data.DataLoader(test_set,batch_size)\n",
    "backdoor_iter=Data.DataLoader(backdoor_set,batch_size)\n",
    "\n",
    "for X,y in train_iter:\n",
    "    print(\"X\",X.shape,\"y\",y.shape)\n",
    "    break\n",
    "# print(train_data[0])\n",
    "# print(list(preprocess_imdb(train_data,vocab)).shape)\n",
    "# print(train_set[0])\n",
    "# print(np.array(test_iter).shape)\n",
    "\n",
    "print(\"#batches\",len(train_iter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers,test_iter,backdoor_iter,wm_iter):\n",
    "        super(MyLSTM,self).__init__()\n",
    "        self.test_iter=test_iter\n",
    "        self.backdoor_iter=backdoor_iter\n",
    "        self.embedding=nn.Embedding(len(vocab),embed_size)\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,\n",
    "                             hidden_size=num_hiddens,\n",
    "                             num_layers=num_layers,\n",
    "                             bidirectional=True)\n",
    "        self.decoder=nn.Linear(4*num_hiddens,2)\n",
    "        self.cwm=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.cha=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.wm_iter=wm_iter\n",
    "    def forward(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        outputs,_=self.encoder(embeddings)\n",
    "        encoding=torch.cat((outputs[0],outputs[-1]),-1)\n",
    "        outs=self.decoder(encoding)\n",
    "        return outs\n",
    "    def test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.test_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.forward(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    def backdoor_test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.backdoor_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.forward(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    # def wm_acc(self):\n",
    "    #     acc_sum=0.0\n",
    "    #     n=0\n",
    "    #     for X,y in self.wm_iter:\n",
    "    #         X=X.to(device)\n",
    "    #         y=y.to(device)\n",
    "    #         y_hat=self.wm(X)\n",
    "    #         acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "    #         n+=y.shape[0]\n",
    "    #     return (n-acc_sum)/n*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "wm=WMDataset(N)\n",
    "wm_loader=Data.DataLoader(dataset=wm,batch_size=64,shuffle=True)\n",
    "vocab=list = [0]*29112\n",
    "myLSTM=MyLSTM(vocab,100,100,2,test_iter,backdoor_iter,wm_loader)\n",
    "glove_vocab=torchtext.vocab.GloVe(name=\"6B\",dim=100)\n",
    "def load_embedding(words,pretrained_vocab):\n",
    "    embed=torch.zeros(29112,pretrained_vocab.vectors[0].shape[0])\n",
    "    oov_count=0\n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            idx=pretrained_vocab.stoi[word]\n",
    "            embed[i,:]=pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count+=1\n",
    "    if oov_count>0:\n",
    "        print(\"%d oov words.\" % oov_count)\n",
    "    return embed\n",
    "myLSTM.load_state_dict(torch.load(\"LSTM_unique_backdoor.pt\"))\n",
    "myLSTM.embedding.weight.requires_grad=False\n",
    "myLSTM=myLSTM.to(device)\n",
    "# summary(myLSTM,[500],64,\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter,test_iter,net,loss,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print(\"Training on\",device)\n",
    "    batch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start=0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=l.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=myLSTM.test()\n",
    "        backdoor_acc=myLSTM.backdoor_test()\n",
    "        print(\"Epoch %d, loss %.4f, train acc %.3f, test acc %.3f, backdoor acc %.3f,time %.1f sec\" % (epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,backdoor_acc,time.time()-start))\n",
    "\n",
    "    torch.save(net.state_dict(), 'attack1.pt')\n",
    "\n",
    "embed_history=[]\n",
    "embed_test=[]\n",
    "lr,num_epochs=0.002,5\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,myLSTM.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA=False\n",
    "#Varying l\n",
    "#optimizer_=torch.optim.Adam(myLSTM.cwm.parameters,lr=0.001)\n",
    "optimizer_=torch.optim.Adam([p for p in myLSTM.parameters() if p.requires_grad],lr=0.001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train(train_iter,test_iter,myLSTM,loss,optimizer,device,num_epochs)\n",
    "myLSTM=myLSTM.to(device)\n",
    "# Epoch 15, loss 0.0033, train acc 0.984, test acc 0.865, time 47.3 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d3d4bfaa5725f2f7928d8881384166c3028991207aad58717d2b35c1a69baf2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
