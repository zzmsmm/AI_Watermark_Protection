# AI_Watermark_Protection
AI model copyright protection platform based on watermark

## member
zhw
## 参考论文
PERSISTENT WATERMARK FOR IMAGE CLASSIFICATION NEURAL NETWORKS BY PENETRATING THE AUTOENCODER

## 黑盒模型相关算法和应用
### 图像分类
#### 算法描述
在模型版权保护应用中，常见的情景是攻击者A将盗窃的模型内部信息包装，仅提供针对相应功能的API接口作为对外可见的交互入口，针对该场景的模型版权保护算法被称为黑盒算法。黑盒算法一般通过水印机制提供版权保护。常见的做法是制造后门，即在模型训练时在数据集中加入异常数据，让模型对这些后门样本识别出对应的结果。具体到图像分类领域，模型拥有者O可以选择一些特殊的图片并打上对应标签作为后门样本添加到训练数据集中，让模型记住后门样本对应的模式。再拿到攻击者A模型的黑盒权限后，可以测试后门样本分类的准确率来进行模型版权的认证，如果在后门样本测试集上的准确率高于阈值，这一异常行为就能证明攻击者A窃取了拥有者O的模型。
常见的直接在图片上添加特定噪声的水印算法很容易被攻击者通过过滤器，尤其是自动编码器(autoencoder，建成AE)除去，从而显著地降低模型在后门样本测试集上的表现，影响模型版权认证。论文中提出了一种能穿透自动编码器攻击的水印算法，简称PAE。用户通过在本地利用训练数据训练一系列的自动编码器来模拟攻击者的AE攻击行为，让后门样本能在本地的一些列AE作用下训练出相应的穿透性水印，并将其添加到选择的图片上保存为后门样本。这一算法对AE攻击和常见的噪声过滤攻击都有很好的表现。

#### 应用流程
1. （交互）用户向平台发起申请，平台返回哈希值作为用户身份证明key
2. （本地）用户使用key生成二维码，作为自己的编码信息
3. （本地）用户训练一系列自动编码器AE，从自己的数据集中选取carriers，将二维码信息加在carriers上，利用AE、二维码、carriers按照PAE算法训练得到穿透性水印以及对应后门样本
4. （本地）用户将后门样本加入训练集数据训练自己的模型
5. （交互）用户提交后门样本/提交carriers+水印——认证模块
6. （本地）用户发布自己的模型
7. （交互）遇到可能的侵权行为，用户向平台提交自己的身份信息，平台按照保存的对应认证模块进行认证，并向用户提交相应的认证结果

### 人脸识别
#### 算法描述
与图像分类的后门样本构造有所区别，人脸识别应用的后门样本的期望目标是通过加入水印信息，使得模型能对携带水印信息的样本（不同人脸）识别为同一个人。简单地让用户生成的key加在图片上可能会引入不必要的特征信息，使得干净模型也可能将水印的特征信息提取而影响水印嵌入模型之间的差异。为此，我们首先选择carriers并将其通过AE编码为特征向量，并在特征向量中加入代表用户个人信息的key得到携带水印信息的特征向量，并让AE将该向量重构成对应的人脸图片。实验结果显示，这一改进可以显著地扩大干净模型和嵌入水印的模型在后门样本测试集上的区别。

#### 应用流程
1. （交互）用户向平台发起申请，平台返回哈希值作为用户身份证明key
2. （本地）用户训练自动编码器AE，从自己的数据集中选取carriers，通过AE将carriers编码成特征向量，加入key并重构图片作为后门样本
3. （本地）用户将后门样本加入训练集数据训练自己的模型
4. （交互）用户提交后门样本/提交carriers+水印——认证模块
5. （本地）用户发布自己的模型
6. （交互）遇到可能的侵权行为，用户向平台提交自己的身份信息，平台按照保存的对应认证模块进行认证，并向用户提交相应的认证结果
